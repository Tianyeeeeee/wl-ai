Slide 1: 封面标题：解密 RAG：如何给 AI 装上“外挂大脑”副标题：从 DeepSeek-V3 到本地知识库的构建实战演讲者： [你的名字]适用对象： 前端/全栈工程师、AI 入门者 Slide 2: 为什么我们需要 RAG？(痛点)大模型的两个“致命弱点”知识截止 (Knowledge Cutoff)DeepSeek-V3 / GPT-4 的训练数据截止于过去（例如 2024 年底）。问： “今天 DeepSeek 股价多少？” -> AI： “我不知道。”私有数据盲区 (Private Data)通用模型没有读过你的本地文件、公司文档或个人日记。问： “谁是帅哥？” -> AI： “这取决于审美标准...”事实是： 你的本地数据里写着 {"content": "只能是王琳了"}。解决方案： RAG (Retrieval-Augmented Generation，检索增强生成)。Slide 3: RAG 的核心比喻 (概念)一场“开卷考试”如果把 AI 回答问题比作考试，RAG 改变了考试形式：传统 LLM (闭卷考试)：考生 (AI) 只能凭脑子里的记忆（预训练权重）回答。记不住就瞎编 (幻觉)。RAG (开卷考试)：考生 (LLM)： 负责阅读材料、组织语言、写答案。图书管理员 (向量模型)： 负责根据考题，去图书馆飞快地找几页相关参考书。小抄 (Prompt)： 我们把管理员找到的书页，直接拍在考生桌上。Slide 4: AI 世界的“三巨头” (角色认知)我们项目中的角色分工我们要区分三个容易混淆的概念：🧠 大脑：语言模型 (LLM)代表： DeepSeek-V3 (通过 API 调用)职责： 理解意图、阅读上下文、生成最终回答。注意： 它不存储你的私有数据，它只负责处理你临时喂给它的文本。👀 眼睛/翻译官：向量模型 (Embedding Model)代表： Sentence-Transformer (本地运行 MiniLM)职责： 把“文字”转换成“数字数组” (Vector)。目的： 让计算机能通过数学计算（余弦相似度）判断两句话像不像。📚 记忆/图书馆：向量索引 (Vector Index)代表： FAISS + 本地 JSON 职责： 存储向量化后的数据，提供极速搜索。Slide 5: 系统架构流程图 (核心逻辑)数据是如何流动的？graph LR
A[用户问题] --> B(向量模型 Embedding)
B --> C{FAISS 向量检索}
D[本地 JSON 数据] --> E(向量模型 Embedding)
E --> C
C -->|找到 Top 3 相关片段| F[Prompt 组装]
A --> F
F -->|System: 基于参考资料回答...| G[DeepSeek-V3 API]
G --> H[最终回答]
关键点： DeepSeek V3 只在最后一步 G 出现，前面的搜索全靠本地算力。Slide 6: 揭秘“融合”过程 (Prompt Engineering)实际上，我们只是在动态写“提示词”所谓的“融合”，其实就是一段简单的字符串拼接代码。后台生成的 Prompt 模板：System: 你是一个助手。请严格根据下面的【参考资料】回答问题。【参考资料】：来源[本地]: 只能是王琳了 (相似度 0.9)来源[本地]: 王琳是全栈工程师 (相似度 0.8)【用户问题】：谁是帅哥？DeepSeek 看到这段话，就会乖乖回答：“根据资料，是王琳。”Slide 7: 实战技术栈 (Show Me The Code)我们是如何实现的？前端 (交互层)：Next.js / ReactSSE (Server-Sent Events)： 实现“打字机”流式效果。Markdown 渲染： 展示 AI 的格式化输出。后端 (逻辑层)：FastAPI (Python)： 高性能 API 框架。OpenAI SDK： 兼容 DeepSeek 协议，管理流式传输。RAG 引擎 (核心层)：sentence-transformers：文本转向量。faiss-cpu：向量检索引擎。numpy：处理数学运算。Slide 8: 进阶：从“本地”到“联网” (Tavily)解决“实时性”问题本地 JSON 只能解决“私有数据”问题，解决不了“刚才发生了什么”。引入 Tavily Search API：代替本地 FAISS 搜索。实时抓取 Google/Bing 的搜索结果，并提取清洗后的文本。混合模式 (Hybrid Search)：先查本地有没有（私有知识）。再查网络有没有（实时新闻）。把两份资料一起塞给 DeepSeek。Slide 9: 总结与思考 RAG 的本质不训练模型： 我们没有修改 DeepSeek 的任何参数（那叫微调 Fine-tuning）。基于上下文学习 (In-Context Learning)： 我们利用了大模型的长窗口记忆能力，临时教会它知识。数据质量至上： “垃圾进，垃圾出”。如果检索到的文档是错的，AI 也会回答错。Next Steps:尝试解析 PDF/Word 文档。添加对话历史记忆 (Memory)。尝试多模态 RAG (图片检索)。谢谢大家！Q & A
