from openai import OpenAI
import os

# 1. é…ç½®ä½ çš„å‚æ•°
API_KEY = "sk-tDCjIrUKeOC4oIot69G4Uf5ubP0TLUACqLcsXYG74PI3HGvs" # ä½ çš„ Key
BASE_URL = "https://aimodels.leapmotor.com/v1" # æ³¨æ„ï¼šè¿™é‡Œä¸è¦å†™ /chat/completions
MODEL_NAME = "deepseek-v3.1"

print(f"ğŸ”„ æ­£åœ¨æµ‹è¯•è¿æ¥: {BASE_URL} ...")

try:
    # 2. åˆå§‹åŒ–å®¢æˆ·ç«¯
    client = OpenAI(api_key=API_KEY, base_url=BASE_URL)

    # 3. å‘èµ·æµå¼è¯·æ±‚
    response = client.chat.completions.create(
        model=MODEL_NAME,
        messages=[{"role": "user", "content": "ä½ å¥½ï¼ŒDeepSeekï¼Œè¯·å›å¤'æµ‹è¯•æˆåŠŸ'å››ä¸ªå­—ã€‚"}],
        stream=True,
        stream_options={"include_usage": True} # ä½ è¦æ±‚çš„å‚æ•°
    )

    print("âœ… è¿æ¥æˆåŠŸï¼æ¥æ”¶æµå¼æ•°æ®ä¸­ï¼š")
    print("-" * 30)

    # 4. æ‰“å°ç»“æœ
    full_content = ""
    for chunk in response:
        # å¤„ç† usage ä¿¡æ¯ (é€šå¸¸åœ¨æœ€åä¸€ä¸ªåŒ…)
        if hasattr(chunk, 'usage') and chunk.usage:
            print(f"\n[Usage Info] Prompt: {chunk.usage.prompt_tokens}, Total: {chunk.usage.total_tokens}")
            continue

        if chunk.choices and len(chunk.choices) > 0:
            delta = chunk.choices[0].delta
            if delta.content:
                print(delta.content, end="", flush=True)
                full_content += delta.content

    print("\n" + "-" * 30)
    print("æµ‹è¯•ç»“æŸã€‚")

except Exception as e:
    print(f"\nâŒ è¿æ¥å¤±è´¥ï¼é”™è¯¯è¯¦æƒ…:\n{e}")
    print("\nè¯·æ£€æŸ¥ï¼š\n1. API Key æ˜¯å¦æ­£ç¡®\n2. pip install --upgrade openai (éœ€è¦æœ€æ–°ç‰ˆæ‰æ”¯æŒ stream_options)")