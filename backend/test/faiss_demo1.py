import numpy as np

# å…ˆå°è¯•å¯¼å…¥faissåº“
try:
    import faiss
    print("âœ… FAISSåº“å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print("âŒ FAISSåº“å¯¼å…¥å¤±è´¥ï¼Œè¯·å®‰è£…faissåº“:")
    print("pip install faiss-cpu  # CPUç‰ˆæœ¬")
    print("pip install faiss-gpu  # GPUç‰ˆæœ¬ï¼ˆéœ€è¦CUDAï¼‰")
    exit(1)

# ç®€å•çš„æ‰‹å·¥å‘é‡ç¼–ç å‡½æ•°ï¼ˆæ¨¡æ‹ŸçœŸå®çš„å‘é‡è¡¨ç¤ºï¼‰
def simple_text_to_vector(text):
    """ç®€å•çš„æ–‡æœ¬è½¬å‘é‡å‡½æ•°ï¼Œç”¨äºæ¼”ç¤º"""
    # è¿™é‡Œæˆ‘ä»¬æ‰‹å·¥æ„é€ ä¸€äº›æœ‰æ„ä¹‰çš„å‘é‡
    # å®é™…åº”ç”¨ä¸­ä¼šä½¿ç”¨BERTã€Sentence-BERTç­‰æ¨¡å‹
    words = text.lower().split()
    vector = np.zeros(16, dtype='float32')  # ä½¿ç”¨16ç»´ä¾¿äºæ¼”ç¤º
    
    # ç®€å•çš„è¯é¢‘ç»Ÿè®¡ + ä½ç½®ç¼–ç 
    word_map = {
        'ai': 0, 'artificial': 0, 'intelligence': 1,
        'ml': 2, 'machine': 2, 'learning': 3,
        'dl': 4, 'deep': 4, 'neural': 5, 'network': 5,
        'computer': 6, 'science': 7, 'data': 8,
        'algorithm': 9, 'model': 10, 'training': 11,
        'python': 12, 'programming': 13, 'code': 14,
        'application': 15
    }
    
    for word in words:
        for key in word_map:
            if key in word:
                vector[word_map[key]] += 1.0
    
    # å½’ä¸€åŒ–
    norm = np.linalg.norm(vector)
    if norm > 0:
        vector = vector / norm
    
    return vector

def demo_faiss_with_real_data():
    """ä½¿ç”¨çœŸå®æ•°æ®çš„FAISSæ¼”ç¤º"""
    print("ğŸš€ FAISSå‘é‡æ£€ç´¢æ¼”ç¤ºï¼ˆçœŸå®æ•°æ®ç‰ˆï¼‰")
    
    # åˆ›å»ºçœŸå®çš„æ–‡æ¡£æ•°æ®
    database_documents = [
        "Artificial Intelligence is a branch of computer science",
        "Machine Learning algorithms can learn from data",
        "Deep Neural Networks are used in deep learning",
        "Python programming language is popular for AI development",
        "Data Science involves statistical analysis and machine learning",
        "Computer vision applications use neural networks",
        "Natural language processing is a subfield of AI",
        "Supervised learning requires labeled training data",
        "Reinforcement learning uses reward-based training",
        "Big data analytics helps business decision making"
    ]
    
    query_documents = [
        "What is artificial intelligence?",
        "How does machine learning work?",
        "Programming languages for AI development",
        "Applications of neural networks",
        "Data analysis techniques"
    ]
    
    dimension = 16  # å‘é‡ç»´åº¦
    
    print("\nğŸ“š æ•°æ®åº“æ–‡æ¡£:")
    for i, doc in enumerate(database_documents):
        print(f"  [{i}] {doc}")
    
    print("\nâ“ æŸ¥è¯¢é—®é¢˜:")
    for i, query in enumerate(query_documents):
        print(f"  [{i}] {query}")
    
    # å°†æ–‡æ¡£è½¬æ¢ä¸ºå‘é‡
    print("\nğŸ”„ å°†æ–‡æ¡£è½¬æ¢ä¸ºå‘é‡...")
    xb = np.array([simple_text_to_vector(doc) for doc in database_documents], dtype='float32')
    xq = np.array([simple_text_to_vector(query) for query in query_documents], dtype='float32')
    
    print(f"\nğŸ“Š å‘é‡å½¢çŠ¶:")
    print(f"   æ•°æ®åº“å‘é‡ (xb): {xb.shape}")  # (10, 16) - 10ä¸ªæ–‡æ¡£ï¼Œ16ç»´å‘é‡
    print(f"   æŸ¥è¯¢å‘é‡ (xq): {xq.shape}")   # (5, 16) - 5ä¸ªæŸ¥è¯¢ï¼Œ16ç»´å‘é‡
    
    # æ˜¾ç¤ºå‰å‡ ä¸ªå‘é‡ç¤ºä¾‹
    print(f"\nğŸ“‹ å‘é‡ç¤ºä¾‹:")
    print(f"   æ–‡æ¡£0å‘é‡: {xb[0][:5]}...")  # æ˜¾ç¤ºå‰5ç»´
    print(f"   æŸ¥è¯¢0å‘é‡: {xq[0][:5]}...")  # æ˜¾ç¤ºå‰5ç»´
    
    # æ–¹æ³•1ï¼šæš´åŠ›æœç´¢ (ç²¾ç¡®æœç´¢)
    print("\nğŸ” æ–¹æ³•1: æš´åŠ›æœç´¢ (ç²¾ç¡®æœç´¢)")
    index_flat = faiss.IndexFlatL2(dimension)
    index_flat.add(xb)
    D, I = index_flat.search(xq, 3)  # è¿”å›3ä¸ªæœ€è¿‘é‚»
    
    print(f"   æœç´¢ç»“æœåˆ†æ:")
    for i in range(len(query_documents)):
        query_text = query_documents[i]
        distances = D[i][:3]
        indices = I[i][:3]
        
        print(f"\n   æŸ¥è¯¢: '{query_text}'")
        print(f"   æœ€è¿‘é‚»:")
        for j, (idx, dist) in enumerate(zip(indices, distances)):
            print(f"     {j+1}. [{idx}] '{database_documents[idx]}' (è·ç¦»: {dist:.3f})")
    
    # æ–¹æ³•2ï¼šIVFç´¢å¼• (è¿‘ä¼¼æœç´¢)
    print("\nğŸ” æ–¹æ³•2: IVFç´¢å¼• (è¿‘ä¼¼æœç´¢)")
    nlist = 3  # èšç±»ä¸­å¿ƒæ•°
    quantizer = faiss.IndexFlatL2(dimension)
    index_ivf = faiss.IndexIVFFlat(quantizer, dimension, nlist)
    
    print("   è®­ç»ƒç´¢å¼•...")
    index_ivf.train(xb)
    
    print("   æ·»åŠ æ•°æ®...")
    index_ivf.add(xb)
    
    D, I = index_ivf.search(xq, 3)
    
    print(f"   æœç´¢ç»“æœåˆ†æ:")
    for i in range(len(query_documents)):
        query_text = query_documents[i]
        distances = D[i][:3]
        indices = I[i][:3]
        
        print(f"\n   æŸ¥è¯¢: '{query_text}'")
        print(f"   æœ€è¿‘é‚»:")
        for j, (idx, dist) in enumerate(zip(indices, distances)):
            print(f"     {j+1}. [{idx}] '{database_documents[idx]}' (è·ç¦»: {dist:.3f})")
    
    print("\nâœ… FAISSæ¼”ç¤ºå®Œæˆ")

if __name__ == "__main__":
    demo_faiss_with_real_data()